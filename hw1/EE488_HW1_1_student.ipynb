{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNL9F-7hI01l"
      },
      "source": [
        "EE488 HW #1: Classification of MNIST Dataset\n",
        "====\n",
        "\n",
        "## Instruction\n",
        "- In this HW assignment, we design a MNIST classifier using convolutional neural network\n",
        "- Complete the code by implementing the architecture described in \"CNN Architecture\" section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRPk2SMeZB1e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as vision_dsets\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_GkGEzRZB1f"
      },
      "source": [
        "## Initilaize Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h53qoNVHZB1f"
      },
      "outputs": [],
      "source": [
        "root='./data'\n",
        "batch_size=32\n",
        "# Use Mnist data for training\n",
        "\n",
        "mnist_train = vision_dsets.MNIST(root = root,\n",
        "                                train = True,\n",
        "                                transform = T.ToTensor(),\n",
        "                                download = True)\n",
        "mnist_test = vision_dsets.MNIST(root = root,\n",
        "                                train = False,\n",
        "                                transform = T.ToTensor(),\n",
        "                                download = True)\n",
        "\n",
        "trainDataLoader = data.DataLoader(dataset = mnist_train,\n",
        "                                    batch_size = batch_size,\n",
        "                                    shuffle =True,\n",
        "                                    num_workers = 1)\n",
        "\n",
        "testDataLoader = data.DataLoader(dataset = mnist_test,\n",
        "                                batch_size = batch_size,\n",
        "                                shuffle = False,\n",
        "                                num_workers = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE_1ORYIZB1h"
      },
      "source": [
        "## Define Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF8aZYCHZB1i"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, net, optimizer, criterion):\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.net = net\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def train(self, epoch = 1, log_freq = 500):\n",
        "        self.net.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0\n",
        "            for i, (inputs, labels) in enumerate(self.trainloader, 0):\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.net(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if (i+1) % log_freq == 0:\n",
        "                    print('[%d, %5d] loss: %.3f' % (e + 1, i + 1, running_loss / log_freq))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished Training')\n",
        "\n",
        "    def test(self):\n",
        "        self.net.eval()\n",
        "\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            output = self.net(inputs)\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "            test_loss /= len(self.testloader.dataset)\n",
        "        print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.\n",
        "                format(correct, len(self.testloader.dataset),\n",
        "                100.* correct / len(self.testloader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8BiMXcmmPol"
      },
      "source": [
        "# CNN Architecture\n",
        "Complete this section to implenent a classifier with 3 CNN layers and 2 FCN layers.\n",
        "\n",
        "Details of architecture are provided in comments below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jow47uKZB1s"
      },
      "outputs": [],
      "source": [
        "## Fill in the empty space\n",
        "# Architecture: 3-layers of CNN, 2-layers of FCN\n",
        "# Layer 1: convolutional layer + batch norm 2d + relu activation\n",
        "#          output channels: 32, kernel size: (2,2), stride: (2,2)\n",
        "# Layer 2: convolutional layer + batch norm 2d + relu activation\n",
        "#          output channels: 64, kernel size: (2,2), stride: (2,2)\n",
        "# Layer 3: convolutional layer + batch norm 2d + relu activation\n",
        "#          output channels: 128, kernel size: (2,2), stride: (2,2)\n",
        "# Layer 4: fully connected layer\n",
        "#          input: flattened 1d vector from Layer 3 output, output channels: 512\n",
        "# Layer 5: fully connected layer: output channels 10 (=number of classes)\n",
        "\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self, hidden1, hidden2, hidden3):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        # Convolutional Layers\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=hidden1, kernel_size=(2, 2), stride=(2, 2)),\n",
        "            nn.BatchNorm2d(hidden1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden1, out_channels=hidden2, kernel_size=(2, 2), stride=(2, 2)),\n",
        "            nn.BatchNorm2d(hidden2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden2, out_channels=hidden3, kernel_size=(2, 2), stride=(2, 2)),\n",
        "            nn.BatchNorm2d(hidden3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Assume MNIST input size: (1, 28, 28)\n",
        "        # Output size after 3 conv layers with stride (2,2) and kernel size (2,2) = (128, 3, 3)\n",
        "        self.fc1 = nn.Linear(hidden3 * 3 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "        # Fill in here\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWbMHN5ZZB1t"
      },
      "outputs": [],
      "source": [
        "mnist_net = MNIST_Net(hidden1= 32, hidden2 = 64, hidden3 = 128).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvNqX3QuZB1t"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(trainloader = trainDataLoader,\n",
        "                  testloader = testDataLoader,\n",
        "                  net = mnist_net,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWxWR2mDZB1t"
      },
      "outputs": [],
      "source": [
        "trainer.train(epoch = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OvxuLwsZB1t"
      },
      "outputs": [],
      "source": [
        "trainer.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57OPBgCKjh0L"
      },
      "source": [
        "# Plotting\n",
        "Below code plots figure of the original input image and predicted probability for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqHKQE8FjiXF"
      },
      "outputs": [],
      "source": [
        "n = 10 # the number of data to be plotted\n",
        "plt.figure(figsize=(10, 20)) # total figure size\n",
        "\n",
        "for i in range(n):\n",
        "    input_image = mnist_test[i][0].cuda() # (1,28,28) tensor\n",
        "    input_ = input_image.unsqueeze(0)     # change to (1,1,28,28)\n",
        "    pred_prob = torch.softmax(mnist_net(input_),dim=1).cpu().detach().squeeze().numpy()\n",
        "\n",
        "    ax = plt.subplot(n, 2, 2*i+1)\n",
        "    plt.imshow(input_image[0].cpu()) # show input image\n",
        "    plt.title('original')\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax2 = plt.subplot(n, 2, 2*i+2)\n",
        "    ax2.set_ylim([0,1])\n",
        "\n",
        "    classify_as = [str(i) for i in range(n)]\n",
        "    plt.bar(classify_as, pred_prob, width = 0.5, tick_label = classify_as) # print predicted probability for each class\n",
        "\n",
        "    plt.title('predicted probability')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
